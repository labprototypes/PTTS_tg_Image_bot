import os
import sys
import openai
from docx import Document
from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from io import BytesIO
import atexit
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from textwrap import wrap
import fitz  # PyMuPDF

# Ð¤Ð°Ð¹Ð»-Ð·Ð°Ð¼Ð¾Ðº
lock_file = "/tmp/bot.lock"
if os.path.exists(lock_file):
    print("Ð‘Ð¾Ñ‚ ÑƒÐ¶Ðµ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½. Ð—Ð°Ð²ÐµÑ€ÑˆÐ°ÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ.")
    sys.exit()
with open(lock_file, "w") as f:
    f.write("running")
atexit.register(lambda: os.remove(lock_file))

# ÐšÐ»ÑŽÑ‡Ð¸
openai.api_key = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")
client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

is_generating_ideas = False
is_active = True

# PDF â†’ Ñ‚ÐµÐºÑÑ‚
def extract_text_from_pdf(file_path):
    doc = fitz.open(file_path)
    return "\n".join(page.get_text() for page in doc)

# DOCX â†’ Ñ‚ÐµÐºÑÑ‚
def extract_text_from_docx(file_path):
    doc = Document(file_path)
    return "\n".join([para.text for para in doc.paragraphs])

# Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¸Ð´ÐµÐ¹
async def generate_ideas_from_brief(brief_text: str) -> str:
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ð¢Ñ‹ ÑÐ¸Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€. Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¸Ð´ÐµÐ¸ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ðµ."},
            {"role": "user", "content": f"Ð’Ð¾Ñ‚ Ð±Ñ€Ð¸Ñ„:\n{brief_text}\nÐ¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐ¹ Ñ€Ð¾Ð²Ð½Ð¾ 5 Ð¸Ð´ÐµÐ¹. Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚:\n1. ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ (ÐºÑ€ÑƒÐ¿Ð½Ð¾)\n2. Ð˜Ð½Ñ‚Ñ€Ð¾\n3. ÐšÑ€Ð°Ñ‚ÐºÐ¾\n4. ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð¾\n5. Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹\n6. ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ð¸Ð´ÐµÑ Ñ…Ð¾Ñ€Ð¾ÑˆÐ°Ñ"}
        ],
        temperature=0.8,
        max_tokens=2500
    )
    return response.choices[0].message.content.strip()

# PDF Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ
def create_pdf(ideas: str) -> BytesIO:
    pdf_output = BytesIO()
    c = canvas.Canvas(pdf_output, pagesize=letter)
    width, height = letter

    font_path = "TT_Norms_Pro_Trial_Expanded_Medium.ttf"
    pdfmetrics.registerFont(TTFont('CustomFont', font_path))

    margin_left = 50
    margin_right = 50
    max_line_width = width - margin_left - margin_right
    font_size = 12
    line_height = 16

    y_position = height - 50

    for idx, idea in enumerate(ideas.strip().split("\n\n"), start=1):
        c.setFont("CustomFont", 16)
        c.drawString(margin_left, y_position, f"Idea {idx}")
        y_position -= 24

        c.setFont("CustomFont", font_size)
        lines = idea.strip().split("\n")

        for line in lines:
            wrapped = wrap(line, width=int(max_line_width / (font_size * 0.55)))
            for part in wrapped:
                if y_position < 50:
                    c.showPage()
                    c.setFont("CustomFont", font_size)
                    y_position = height - 50
                c.drawString(margin_left, y_position, part)
                y_position -= line_height
            y_position -= 4
        y_position -= 20

    c.save()
    pdf_output.seek(0)
    return pdf_output

# ÐšÐ¾Ð¼Ð°Ð½Ð´Ñ‹
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("Ð‘Ð¾Ñ‚ Ð±Ñ‹Ð» Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("Ð¡ÐµÐ¹Ñ‡Ð°Ñ Ñ Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð´ÐµÐ¸. ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾.")
    else:
        await update.message.reply_text("ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð¢Ñ‹ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ð¾Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ ÑÐ¾ Ð¼Ð½Ð¾Ð¹, Ð¸Ð»Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ Ð±Ñ€Ð¸Ñ„ Ð² PDF/DOC â€” Ð¸ Ñ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÑŽ Ð¸Ð´ÐµÐ¸.")

async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_active
    is_active = False
    await update.message.reply_text("Ð‘Ð¾Ñ‚ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ /start.")

# ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("Ð‘Ð¾Ñ‚ Ð±Ñ‹Ð» Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("ÐŸÐ¾Ð´Ð¾Ð¶Ð´Ð¸, Ñ ÐµÑ‰Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰Ð¸Ð¹ Ð±Ñ€Ð¸Ñ„.")
        return

    is_generating_ideas = True
    await update.message.reply_text("Ð‘Ñ€Ð¸Ñ„ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½. Ð§Ð¸Ñ‚Ð°ÑŽ Ð¸ Ð´ÑƒÐ¼Ð°ÑŽ...")

    document = update.message.document
    file = await document.get_file()
    file_path = f"/tmp/{document.file_name}"
    await file.download_to_drive(file_path)

    if file_path.endswith(".pdf"):
        brief_text = extract_text_from_pdf(file_path)
    elif file_path.endswith(".docx"):
        brief_text = extract_text_from_docx(file_path)
    else:
        await update.message.reply_text("Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ„Ð°Ð¹Ð»Ð° Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ÑÑ. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒÑ‚Ðµ PDF Ð¸Ð»Ð¸ DOCX.")
        is_generating_ideas = False
        return

    ideas = await generate_ideas_from_brief(brief_text)
    pdf_file = create_pdf(ideas)

    await update.message.reply_document(document=InputFile(pdf_file, filename="ideas.pdf"))
    await update.message.reply_text("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾! ÐœÐ¾Ð¶ÐµÐ¼ ÑÐ½Ð¾Ð²Ð° Ð±Ð¾Ð»Ñ‚Ð°Ñ‚ÑŒ ðŸ™‚")

    is_generating_ideas = False

# Ð¡Ð²Ð¾Ð±Ð¾Ð´Ð½Ñ‹Ð¹ Ð´Ð¸Ð°Ð»Ð¾Ð³
async def chat_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("Ð‘Ð¾Ñ‚ Ð±Ñ‹Ð» Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½. Ð”Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶ÐµÐ½Ð¸Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("Ð¡ÐµÐºÑƒÐ½Ð´Ñƒ, Ñ ÐµÑ‰Ðµ Ð´ÑƒÐ¼Ð°ÑŽ Ð½Ð°Ð´ Ð¸Ð´ÐµÑÐ¼Ð¸. Ð¡ÐºÐ¾Ñ€Ð¾ Ð²ÐµÑ€Ð½ÑƒÑÑŒ!")
        return

    user_message = update.message.text
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ð¢Ñ‹ ÑƒÐ¼Ð½Ñ‹Ð¹ Ð¸ Ð´Ð¾Ð±Ñ€Ð¾Ð¶ÐµÐ»Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚, Ð¾Ð±Ñ‰Ð°Ð¹ÑÑ Ð² ÑÐ²Ð¾Ð±Ð¾Ð´Ð½Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ðµ."},
            {"role": "user", "content": user_message}
        ],
        temperature=0.7,
        max_tokens=800
    )
    await update.message.reply_text(response.choices[0].message.content.strip())

# Ð—Ð°Ð¿ÑƒÑÐº Ð±Ð¾Ñ‚Ð°
def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("stop", stop))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), chat_mode))
    app.run_polling()

if __name__ == "__main__":
    main()

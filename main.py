import os
import openai
from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from fpdf import FPDF
from io import BytesIO

# –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–µ–π –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
openai.api_key = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")

is_generating_ideas = False

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI (–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))


# GPT-4o –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
async def generate_ideas_from_brief(brief_text: str) -> str:
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢—ã —Å–∏–ª—å–Ω—ã–π –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä. –ì–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –∏–¥–µ–∏ —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ."},
            {"role": "user", "content": f"–í–æ—Ç –±—Ä–∏—Ñ:\n{brief_text}\n–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 5 –∏–¥–µ–π. –§–æ—Ä–º–∞—Ç:\n1. –ù–∞–∑–≤–∞–Ω–∏–µ (–∫—Ä—É–ø–Ω–æ)\n2. –ò–Ω—Ç—Ä–æ\n3. –ö—Ä–∞—Ç–∫–æ\n4. –ü–æ–¥—Ä–æ–±–Ω–æ\n5. –°—Ü–µ–Ω–∞—Ä–∏–π\n6. –ü–æ—á–µ–º—É –∏–¥–µ—è —Ö–æ—Ä–æ—à–∞—è"}
        ],
        temperature=0.8,
        max_tokens=2500
    )
    return response.choices[0].message.content.strip()


# PDF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
def create_pdf(ideas: str) -> BytesIO:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞
    font_path = "TT_Norms_Pro_Trial_Expanded_Medium.ttf"
    pdf.add_font("TTNorms", "", font_path, uni=True)
    pdf.set_font("TTNorms", size=12)

    for idx, idea in enumerate(ideas.split("\n\n"), start=1):
        pdf.set_font("TTNorms", size=16)
        pdf.cell(0, 10, f"Idea {idx}", ln=True)
        pdf.set_font("TTNorms", size=12)
        for line in idea.strip().split("\n"):
            pdf.multi_cell(0, 10, line)
        pdf.ln(5)

    pdf_output = BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output


# /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas
    if is_generating_ideas:
        await update.message.reply_text("–°–µ–π—á–∞—Å —è –≥–µ–Ω–µ—Ä–∏—Ä—É—é –∏–¥–µ–∏. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ.")
    else:
        await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –¢—ã –º–æ–∂–µ—à—å –ø—Ä–æ—Å—Ç–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å–æ –º–Ω–æ–π, –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –±—Ä–∏—Ñ –≤ PDF/DOC ‚Äî –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é –∏–¥–µ–∏.")


# –§–∞–π–ª-–±—Ä–∏—Ñ
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas
    if is_generating_ideas:
        await update.message.reply_text("–ü–æ–¥–æ–∂–¥–∏, —è –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±—Ä–∏—Ñ.")
        return

    is_generating_ideas = True
    await update.message.reply_text("–ë—Ä–∏—Ñ –ø–æ–ª—É—á–µ–Ω. –ß–∏—Ç–∞—é –∏ –¥—É–º–∞—é...")

    document = update.message.document
    file = await document.get_file()
    file_path = f"/tmp/{document.file_name}"
    await file.download_to_drive(file_path)

    # ‚ö†Ô∏è –ó–∞–≥–ª—É—à–∫–∞: –≤—Å—Ç–∞–≤—å —Å—é–¥–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É PDF/DOC
    with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
        brief_text = f.read()

    ideas = await generate_ideas_from_brief(brief_text)
    pdf_file = create_pdf(ideas)

    await update.message.reply_document(document=InputFile(pdf_file, filename="ideas.pdf"))
    await update.message.reply_text("–ì–æ—Ç–æ–≤–æ! –ú–æ–∂–µ–º —Å–Ω–æ–≤–∞ –±–æ–ª—Ç–∞—Ç—å üôÇ")

    is_generating_ideas = False


# –°–≤–æ–±–æ–¥–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ —Å –±–æ—Ç–æ–º (–µ—Å–ª–∏ –Ω–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
async def chat_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas
    if is_generating_ideas:
        await update.message.reply_text("–°–µ–∫—É–Ω–¥—É, —è –µ—â–µ –¥—É–º–∞—é –Ω–∞–¥ –∏–¥–µ—è–º–∏. –°–∫–æ—Ä–æ –≤–µ—Ä–Ω—É—Å—å!")
        return

    user_message = update.message.text
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢—ã —É–º–Ω—ã–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ–±—â–∞–π—Å—è –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ."},
            {"role": "user", "content": user_message}
        ],
        temperature=0.7,
        max_tokens=800
    )
    answer = response.choices[0].message.content.strip()
    await update.message.reply_text(answer)


# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), chat_mode))

    app.run_polling()


if __name__ == "__main__":
    main()

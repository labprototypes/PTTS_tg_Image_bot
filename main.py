import os
import sys
import openai
import fitz  # PyMuPDF
from docx import Document
from telegram import Update, InputFile
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters
from fpdf import FPDF
from io import BytesIO
import atexit

# –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª-–∑–∞–º–æ–∫, –µ—Å–ª–∏ –±–æ—Ç —É–∂–µ –∑–∞–ø—É—â–µ–Ω ‚Äî –≤—ã—Ö–æ–¥–∏–º
lock_file = "/tmp/bot.lock"

if os.path.exists(lock_file):
    print("–ë–æ—Ç —É–∂–µ –∑–∞–ø—É—â–µ–Ω. –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å.")
    sys.exit()

with open(lock_file, "w") as f:
    f.write("running")

# –ü—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ ‚Äî —É–¥–∞–ª–∏–º –∑–∞–º–æ–∫
atexit.register(lambda: os.remove(lock_file))

# –ó–∞–≥—Ä—É–∑–∫–∞ API –∫–ª—é—á–µ–π –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
openai.api_key = os.getenv("OPENAI_API_KEY")
BOT_TOKEN = os.getenv("BOT_TOKEN")

is_generating_ideas = False
is_active = True  # –§–ª–∞–≥ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –±–æ—Ç–∞

# –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è OpenAI (–Ω–æ–≤–∞—è –≤–µ—Ä—Å–∏—è)
client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF
def extract_text_from_pdf(file_path):
    doc = fitz.open(file_path)
    text = ""
    for page in doc:
        text += page.get_text()
    return text

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOCX
def extract_text_from_docx(file_path):
    doc = Document(file_path)
    text = "\n".join([para.text for para in doc.paragraphs])
    return text

# GPT-4o –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
async def generate_ideas_from_brief(brief_text: str) -> str:
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢—ã —Å–∏–ª—å–Ω—ã–π –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –¥–∏—Ä–µ–∫—Ç–æ—Ä. –ì–µ–Ω–µ—Ä–∏—Ä—É–π –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–µ –∏–¥–µ–∏ —Å—Ç—Ä–æ–≥–æ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ."},
            {"role": "user", "content": f"–í–æ—Ç –±—Ä–∏—Ñ:\n{brief_text}\n–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 5 –∏–¥–µ–π. –§–æ—Ä–º–∞—Ç:\n1. –ù–∞–∑–≤–∞–Ω–∏–µ (–∫—Ä—É–ø–Ω–æ)\n2. –ò–Ω—Ç—Ä–æ\n3. –ö—Ä–∞—Ç–∫–æ\n4. –ü–æ–¥—Ä–æ–±–Ω–æ\n5. –°—Ü–µ–Ω–∞—Ä–∏–π\n6. –ü–æ—á–µ–º—É –∏–¥–µ—è —Ö–æ—Ä–æ—à–∞—è"}
        ],
        temperature=0.8,
        max_tokens=2500
    )
    return response.choices[0].message.content.strip()

# PDF –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
def create_pdf(ideas: str) -> BytesIO:
    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞
    font_path = "TT_Norms_Pro_Trial_Expanded_Medium.ttf"
    pdf.add_font("TTNorms", "", font_path, uni=True)
    pdf.set_font("TTNorms", size=12)

    for idx, idea in enumerate(ideas.split("\n\n"), start=1):
        pdf.set_font("TTNorms", size=16)
        pdf.cell(0, 10, f"Idea {idx}", ln=True)
        pdf.set_font("TTNorms", size=12)
        for line in idea.strip().split("\n"):
            pdf.multi_cell(0, 10, line)
        pdf.ln(5)

    pdf_output = BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output

# /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("–ë–æ—Ç –±—ã–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ—Ç–ø—Ä–∞–≤—å /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("–°–µ–π—á–∞—Å —è –≥–µ–Ω–µ—Ä–∏—Ä—É—é –∏–¥–µ–∏. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ.")
    else:
        await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –¢—ã –º–æ–∂–µ—à—å –ø—Ä–æ—Å—Ç–æ –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å–æ –º–Ω–æ–π, –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å –±—Ä–∏—Ñ –≤ PDF/DOC ‚Äî –∏ —è —Å–≥–µ–Ω–µ—Ä–∏—Ä—É—é –∏–¥–µ–∏.")

# /stop
async def stop(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_active
    is_active = False
    await update.message.reply_text("–ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ—Ç–ø—Ä–∞–≤—å /start.")

# –§–∞–π–ª-–±—Ä–∏—Ñ
async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("–ë–æ—Ç –±—ã–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ—Ç–ø—Ä–∞–≤—å /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("–ü–æ–¥–æ–∂–¥–∏, —è –µ—â–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø—Ä–µ–¥—ã–¥—É—â–∏–π –±—Ä–∏—Ñ.")
        return

    is_generating_ideas = True
    await update.message.reply_text("–ë—Ä–∏—Ñ –ø–æ–ª—É—á–µ–Ω. –ß–∏—Ç–∞—é –∏ –¥—É–º–∞—é...")

    document = update.message.document
    file = await document.get_file()
    file_path = f"/tmp/{document.file_name}"
    await file.download_to_drive(file_path)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
    if file_path.endswith(".pdf"):
        brief_text = extract_text_from_pdf(file_path)
    elif file_path.endswith(".docx"):
        brief_text = extract_text_from_docx(file_path)
    else:
        await update.message.reply_text("–§–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF –∏–ª–∏ DOCX.")
        is_generating_ideas = False
        return

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–¥–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPT-4o
    ideas = await generate_ideas_from_brief(brief_text)
    pdf_file = create_pdf(ideas)

    await update.message.reply_document(document=InputFile(pdf_file, filename="ideas.pdf"))
    await update.message.reply_text("–ì–æ—Ç–æ–≤–æ! –ú–æ–∂–µ–º —Å–Ω–æ–≤–∞ –±–æ–ª—Ç–∞—Ç—å üôÇ")

    is_generating_ideas = False

# –°–≤–æ–±–æ–¥–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ —Å –±–æ—Ç–æ–º (–µ—Å–ª–∏ –Ω–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
async def chat_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    global is_generating_ideas, is_active
    if not is_active:
        await update.message.reply_text("–ë–æ—Ç –±—ã–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –æ—Ç–ø—Ä–∞–≤—å /start.")
        return
    if is_generating_ideas:
        await update.message.reply_text("–°–µ–∫—É–Ω–¥—É, —è –µ—â–µ –¥—É–º–∞—é –Ω–∞–¥ –∏–¥–µ—è–º–∏. –°–∫–æ—Ä–æ –≤–µ—Ä–Ω—É—Å—å!")
        return

    user_message = update.message.text
    response = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "–¢—ã —É–º–Ω—ã–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –æ–±—â–∞–π—Å—è –≤ —Å–≤–æ–±–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–µ."},
            {"role": "user", "content": user_message}
        ],
        temperature=0.7,
        max_tokens=800
    )
    answer = response.choices[0].message.content.strip()
    await update.message.reply_text(answer)

# –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—É—Å–∫
def main():
    app = ApplicationBuilder().token(BOT_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("stop", stop))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), chat_mode))

    app.run_polling()

if __name__ == "__main__":
    main()
